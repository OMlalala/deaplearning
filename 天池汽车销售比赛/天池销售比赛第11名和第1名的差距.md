# 撩汉记之天池比赛第11名和第1名的差距	
----
## 背景
- 浆糊队第一名0.87分，我们第十一名0.97分
- 就在三天前，复赛我们第一名，浆糊队第六名
- 不甘心啊啊啊......
----
## 撩汉记之初体验
- 3月16号中午加了钉钉好友
- 分享我们队伍的宏观策略
- 询问浆糊君宏观策略
---
## 我们的策略
- A榜，一直采用连续月预测下月的模式预测2018年1月
- B榜，我们采用了三种策略
	- 第一种策略，继续A榜的连续月预测2月
		- 利：我们有所有小组误差最小的2018年1月数据
		- 弊：需要2018年1月数据，会引入误差
	- 第二种策略，隔月预测2月
		- 利：不需要1月数据，不会引入误差
		- 弊：从来没有线上测试过，也没有机会线上测试，只能本地测试
	- 第三种策略：双月预测，直接预测1月2月的销量和、销量差、销量积和销量和
		- 利：可以产生更多的预测结果进行融合
		- 弊：从来没有线上测试过，也没有机会线上测试，只能本地测试
	- 最终选择了第一种策略
		- 策略二测试了一天，只在本地测试，效果不理想
		- 策略三测试了半天，只在本地测试，效果不理想	
---
## 第一名的策略
- A榜，隔月预测2018年1月数据，策略和我们B榜的策略二相同
- B榜，隔月预测2018年2月数据
	- 利：不需要1月数据，不会引入误差，并且模型已经在A榜线上多次验证过了
	- A榜和B榜使用相同的策略，同时在本地和线上测试了至少7天
---
## 撩汉记之深入篇
- 3月16号下午5点尝试询问敏感问题——特征工程和模型
---
		
## 特征工程
- 最重要的特征
	- 销量和产量
	- 加入汽车配置特征，可以把成绩提高0.03
- 我们和第一名的特征差异
	- 第一名使用前2个月到前12个月销量和一共11个特征， 我们只使用了前2个月和前12个月销量和这2个特征
	- 第一名使用了2个月到前12个月产量共11个特征，我们只使用了前2个月产量这1个特征
---

## 模型
- 我们使用xgboost和gbdt融合
- 第一名只使用xgboost单模型，而且迭代次数只有1200次，我们有4200次
---
## 撩汉记之深入深入篇
- 3月16号晚上9点再试探性的询问敏感话题
- 大周五的晚上，结果秒回信息，基本可以判断单身，没有女朋友
---
## 调试方法
- 增减特征工程
	- 我们以本地验证集的成绩好坏为依据，来增减特征工程
	- 第一名提取的所有特征工程全都用上了，并没有进行增减，理由是模型会自动选择增益大的特征去分裂，并且指出我们的做法，可能会刻意拟合验证集数据，减少了模型的泛化性能
---
## 调试方法
- 如何增加模型的泛化性能
	- 我们的方法，切分多个训练集和验证集，分别验证17年1月、2月以及10月、11月、12月的效果差异
	- 只切分了两个训练集验证17年11月和12月，但是会用训练模型来预测训练集得到一个误差值，用这个误差值和模型预测验证集的值进行比较，判断是过拟合还是欠拟合
---
## 撩汉记之交心篇
- 互相开聊个人经历
- 了解第一名队伍背景
---
## 我们的队伍背景
- 成员4名
- 历川、阿虎2017年11月开始学习机器学习和深度学习，蔡俊从2018年2月开始学习机器学习和深度学习，大妈(大家都太过了解不用介绍)
- 比赛期间主力队员投入精力：每天投入8小时
- 第一次参加比赛
---
## 第一名队伍背景
- 成员3人
- 都是武汉大学在校研一学生
- 大一大二打了两年LOL，大三大四搞了2年Java
- 研一搞web开发…
- 主力队员17年9月开始自学机器学习和深度学习
- 比赛期间投入精力：每天投入6到8个小时
- 第一次参加比赛
---
